<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8"/>
	<title>Artificial Intelligence</title>  
	<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
	<link href="style.css" rel="stylesheet" type="text/css" />
	<style>h1,h2{background:#607994}</style>
	<style>#footer{background:#97babb}</style>
</head>
<body id="project">
<div id="header">
	<img id="logo" src="img/logo.png" alt="Brigitte Kozena"/>
	<ul id="menu"><li><a href="index.html">home</a></li><li><a href="index.html#banner">about me</a></li><li><a href="index.html#portfolio">portfolio</a></li><li><a href="index.html#resume">resume</a></li><li><a href="index.html#contact">contact</a></li></ul>
	<img id="mnu" src="img/menu.png" alt=""/>
</div>
<div id="BannerDiv">
	<img id="Banner" src="img/projects/ai/banner.jpg" alt=""/>
</div>
<section>
	<h1>Project: <span>Artificial Intelligence</span><br/></h1>
	<p>During my time at NYU I focused deeply in Artificial Intelligence and the future of mankind. I was inspired greatly by Ray Kurzweil's book, 'The Singularity is Near' leading me to concentrate in the subject at Gallatin. Here is a snippet of some of my work.</p>
			<p class="nav"><a href="crabazon.html">previous</a>|<a href="skyler.html">next</a></p>
	
<h2>The Evolution - Man to Human 2.0/Robot</h2>
<p>Where are we heading as a species? Will our next generation be robots? Or will we transcend to Human 2.0? It is clear from history that change is inevitable and Charles Darwin has showed us our transition from apes in The Origin of Species. While evolving we have seen a number of morphological, physiological, developmental, and behavioral changes. However, we should note that the most significant change is in the size of the brain. Will our brain continue to grow?  Or will we replace our brain with a computer? 
Our species places great value on brain size, which it associates with intelligence as our main characteristic—indeed, we refer to ourselves as Homo sapiens  (Latin for “wise man”).   For thousands of years we have tried to understand how we think. Not only have we tried to understand it, but also we are attempting to recreate it. We refer to this recreation of the human mind as “artificial intelligence”. We will begin by looking at the word “artificial”.</p>  
<p>The English word “artificial” is derived from the Latin word ars meaning “the skill of making anything.” Aristotle, in Physics, states that things that “exist by nature” have “an internal source of change and staying unchanged”.  With artificial objects, however, “the source is in something else and external”.   What he means by this is that natural objects cause changes from within while artificial objects rely on external sources for change. Take for example, a building.  It requires a builder; therefore it is regarded as artificial.  The “maker” is usually human or divine, but today we are building A.I. systems that can in effect build themselves, automatically, without human assistance.   We are creating self-correcting, self-maintaining subprograms. Thus, if take into account the Law of Accelerating Returns, which can be found in Ray Kurzweil’s book, The Singularity is Near, we can see that technology is exponentially evolving without human involvement. This suggests a future where robots may no longer need an external source for change. So, if we remove humans from the equation in this way, does that mean that robots should no longer be regarded as artificial? Should we regard them as living beings (an idea Asimov entertains in his novel I, Robot)? </p>
<p>The answer will depend on how we define the word “intelligence” and how we try to replicate it.  What is intelligence--and how can we measure it? Alan Turing in his paper Computing Machinery and Intelligence created a test to evaluate how smart a machine was. In order to pass the test the human must believe that the robot is also a human. But what does this test actually gauge? Does this mean that we consider humans to be the most intelligent entity on our planet? Even if we do, each human varies in intelligence; the test would depend on who the examiner was and it is not clear that we could devise a test that would fairly compare human and artificial intelligence. Finally, will this stop robots from exceeding past humans? Ray Kurzweil’s movie, The Singularity is Near, makes this point in having Ramona, a superhero avatar, dumb down her answers in order to pass the Turing Test and prove that she is human.   Similarly, human intelligence will permit behaviour that A.I. would not and as Darwin said, even “An American monkey, after getting drunk on brandy, would never touch it again, and thus is much wiser than most men” . Darwin believed that “intelligence was based on how efficient a species became at doing the thing it needs to do to survive”—and yet human beings (unlike other creatures) often choose to do things whose evolutionary benefit isn’t clear.   Would a robot do that?   If so, then it would mean that the robot would have to be conscious of their existence, because making a choice between that which is purely rational and that which is purely pleasurable (i.e. drunk) and not conducive to species survival.  In the Sixth Meditation, Descartes said, "But what then am I? A thing that thinks. What is that? A thing that doubts, understands, affirms, denies, wills, refuses, and which also imagines and senses." </p>
<p>If Descartes understands conscious existence to encompass all those things, modern scientists are less interested in the expansiveness of the soul and more focused on looking at the human body as a computer.  This is not, however, a new phenomenon. Leonardo De Vinci, for example, approached the human body through the architectural principles of Vitruvius and later writers, including Darwin, held this materialistic perspective, believing that the body was a complex machine. This leads us to ask the question, are we humans merely machines? What really is the mind? Is it different from the body, as dualists (such as Plato and Descartes) believed, and as writers, such as Ovid, depicted.  In Metamorphoses, in the story known as “Pygmalion,” a statue, known later as Galatea, has the goddess Aphrodite breathe life into her. This “breath of life” is referred to as “the soul.” Through these stories we understand that it is the soul and spirit that really define us from animals and other living created.  But are these just words summing up science we previously could not understand?</p>
<p>Human beings have encountered questions like this when developing stories about the “creation” of the world.   It comes up as a problem immediately in the Bible, for instance.  According to Genesis 1:26-28 we can distinguish between man and animal in five ways: Man has rational intelligence. Man has will and power to choose. Man has emotions. Man has a conscious. Man has a spirit. However, when we look at the creation of man we begin to question how we attained these features. In Genesis 2.7 he writes, “Then the LORD God formed man of dust from the ground, and breathed into his nostrils the breath of life; and man became a living being.” What we initially learn from this is that God creates two separate entities: the “Body” and the “Soul”. The former is physical, either a direct creation of God or by the process such as evolution by natural selection. The later, appears to be a divine force. But when reading this text, we see that he has given the exact same “breath of life” to the animals. So the ‘breath of life’ does not suggest him giving a soul, but rather you can “become” a living soul. Yet, he never clearly expresses how to attain this “soul”. </p>
<p>How the soul enters the creature (an animal, a robot) comes up in a number of texts, ranging from texts about reincarnation (e.g. Michaels’s theory called “35 steps of Soul Evolution”) to social psychology (such as Maslow’s Hierarchy of Needs) to science fiction (e.g. Blade Runner, in which robots must be killed once they begin to develop human feelings). This makes us question whether robots actually need to be created with a soul? Or is it something they will develop over the years? And if they develop a soul what moral and ethical implications must humans consider? Already in Japan they have created pet robots that have such realistic emotions causing their owners to give them official funerals. This shows that we already are becoming attached to robots even when they do not have consciousness. But what if robots do become self-aware? Will they stay as our pets and employees or will they revolt against us? 
Very often in literature we frequently find a lot of pessimism about A.I. If we consider the time of the industrial revolution, where machines began to be feared by the public, we begin to see hear stories about robots gaining emotion and threatening humanity. Mary Shelly in Frankenstein shows us what may happen when a (kind of) robot gains a conscience and emotions but proceeds to murder humans.  Prometheus similarly shows a tale where species kill their creators.  And to some extent these authors and scriptwriters are right. Machines are beginning to control us and thus, already have more power than us in certain instances. However, in most of these stories we see that the acts of violence from robots begin when we try to eradicate them. Is self-defence really a crime? If we create laws and rights for the robots will this help the merge of the two species?</p>
<p>I, Robot by Issac Asimov in fact does this. He established the three laws of robotics. In these laws he protects humans from robots and robots from humans. Although there are a few issues with these laws, he does a good job in delivering a world where humans and machines are able to live in harmony. 
But even when robots and humans live in harmony we stumble across issues of humans’ self-purpose. If we look at the play Rossum’s Universal Robots by Karel Capek (who invented the word “Robot”) we see robots being used as slaves until they revolt and begin to kill human beings. Not only does this show another instance where robots spiral out of control, but Capek also questions why human existence is necessary at all if robots can be manufactured and take care of everything.  What is the purpose of human existence? 
Although we have discussed the issues between human and robot we must not forget about Human 2.0, a hybrid of the two. This concept of transhumanism will help us keep up with robots both physically and mentally. However, this brings up a number of concerns. At what point are you regarded as a robot? 50%? Will only the rich benefit from this? How is this fair? What about the prospect of immortality? Are humans prepared to live forever? Is death not important to our purpose in life?</p>
<p>With all these foreseen problems lying ahead of us it would be easy to that we should end the research towards A.I. instantly. However, Kurzweil explains that change is inevitable: “ We didn’t stay on the ground. We didn’t stay on the planet. Our species always transcends.”  The problem lies in the fact that the knowledge is already out there, and like anything, A.I. can be used for both the good and evil. Kurzweil argues that if we do not continue to legally support the future of human-level intelligence, this industry will revert underground. This will lead to more harm then good, as it will be out of the control of those who wish to invent for the better of mankind.  As Darwin said, “its not the strongest species that survive, not the most intelligent but he one most responsive to change.”
I do not have a problem with the idea of us evolving into “bots”; part of me believes our species should become extinct in order for earth to survive. Maybe, computers will be able to take our place in the world and fix the harm we have done. However, my only problem lies in the fact that we have created the machines by conscious selection. By allowing us to play God, our next generation may hold our selfish needs and beliefs. As Darwin said, “ man selects only for the good of his own – nature only for that of the being she tends” </p>
 

	
</section>

<div id="footer">
	<a href="crabazon.html">previous</a>|<a href="skyler.html">next</a>
</div>

<script src="project.js" ></script>
</body>
</html>
